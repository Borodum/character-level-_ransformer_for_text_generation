{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading text...\n",
      "creating vocabulary...\n",
      "Total characters: 1115394\n",
      "Unique characters: 65\n",
      "Characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']...\n",
      "creating sequences...\n",
      "Overall sequences: 5414\n",
      "splitting into train/val/test...\n",
      "Train: 4331\n",
      "Val: 541\n",
      "Test: 542\n",
      "saving data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# constants\n",
    "SEQ_LENGTH = 256\n",
    "OVERLAP = 50\n",
    "STRIDE = SEQ_LENGTH - OVERLAP  # 206\n",
    "\n",
    "SCRIPT_DIR = os.getcwd()\n",
    "DATA_PATH = os.path.join(SCRIPT_DIR, \"tiny-shakespeare\", \"input.txt\")\n",
    "\n",
    "\n",
    "# text load\n",
    "def load_text(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "# vocab creation\n",
    "def create_vocab(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    vocab_size = len(chars)\n",
    "    \n",
    "    char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "    idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "    \n",
    "    print(f'Total characters: {len(text)}')\n",
    "    print(f'Unique characters: {vocab_size}')\n",
    "    print(f'Characters: {chars[:50]}...')\n",
    "    \n",
    "    return char_to_idx, idx_to_char, chars\n",
    "\n",
    "def create_sequences(text, char_to_idx, seq_length=256, stride=206):\n",
    "    sequences = []\n",
    "    text_as_int = [char_to_idx[ch] for ch in text]\n",
    "    \n",
    "    for i in range(0, len(text_as_int) - seq_length + 1, stride):\n",
    "        seq = text_as_int[i:i + seq_length]\n",
    "        sequences.append(seq)\n",
    "    \n",
    "    return np.array(sequences)\n",
    "\n",
    "# train/val/test split (no shuffle)\n",
    "def split_sequences(sequences, train_ratio=0.8, val_ratio=0.1):\n",
    "    n = len(sequences)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = int(n * (train_ratio + val_ratio))\n",
    "    \n",
    "    train = sequences[:train_end]\n",
    "    val = sequences[train_end:val_end]\n",
    "    test = sequences[val_end:]\n",
    "    \n",
    "    return train, val, test\n",
    "\n",
    "def main():\n",
    "    print(\"loading text...\")\n",
    "    text = load_text(DATA_PATH)\n",
    "    \n",
    "    print(\"creating vocabulary...\")\n",
    "    char_to_idx, idx_to_char, chars = create_vocab(text)\n",
    "    \n",
    "    print(\"creating sequences...\")\n",
    "    stride = SEQ_LENGTH - OVERLAP\n",
    "    sequences = create_sequences(text, char_to_idx, SEQ_LENGTH, stride)\n",
    "    print(f\"Overall sequences: {len(sequences)}\")\n",
    "    \n",
    "    print(\"splitting into train/val/test...\")\n",
    "    train, val, test = split_sequences(sequences)\n",
    "    \n",
    "    print(f\"Train: {len(train)}\")\n",
    "    print(f\"Val: {len(val)}\")\n",
    "    print(f\"Test: {len(test)}\")\n",
    "    \n",
    "    print(\"saving data...\")\n",
    "    np.save('train.npy', train)\n",
    "    np.save('val.npy', val)\n",
    "    np.save('test.npy', test)\n",
    "    \n",
    "    with open('char_to_idx.pkl', 'wb') as f:\n",
    "        pickle.dump(char_to_idx, f)\n",
    "    with open('idx_to_char.pkl', 'wb') as f:\n",
    "        pickle.dump(idx_to_char, f)\n",
    "    with open('chars.pkl', 'wb') as f:\n",
    "        pickle.dump(chars, f)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
